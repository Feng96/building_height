{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import leafmap\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
>>>>>>> 76472dc1535b057a6ef41f75fc854cef39dadcea
    "import time"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Illinois</th>\n",
       "      <th>IL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>KY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Illinois  IL\n",
       "0    Indiana  IN\n",
       "1       Iowa  IA\n",
       "2     Kansas  KS\n",
       "3   Kentucky  KY\n",
       "4  Louisiana  LA"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headerList = ['State','Abbr' ]\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/Feng96/building_height/main/osm_state_index.csv'\n",
    "states = pd.read_csv(url)\n",
    "states.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing IN ...\n",
      "get centroid of IN\n",
      "creating centroid data frame\n",
      "loading IN building dataset\n",
      "IN spatial joining...\n",
      "write the output to .shp file...\n",
      "IN completed\n",
      "Processing IA ...\n",
      "get centroid of IA\n",
      "creating centroid data frame\n",
      "loading IA building dataset\n",
      "IA spatial joining...\n",
      "write the output to .shp file...\n",
      "IA completed\n",
      "Processing KS ...\n",
      "get centroid of KS\n",
      "creating centroid data frame\n",
      "loading KS building dataset\n",
      "KS spatial joining...\n",
      "write the output to .shp file...\n",
      "KS completed\n",
      "Processing KY ...\n",
      "get centroid of KY\n",
      "creating centroid data frame\n",
      "loading KY building dataset\n",
      "KY spatial joining...\n",
      "write the output to .shp file...\n",
      "KY completed\n",
      "Processing LA ...\n",
      "get centroid of LA\n",
      "creating centroid data frame\n",
      "loading LA building dataset\n",
      "LA spatial joining...\n",
      "write the output to .shp file...\n",
      "LA completed\n",
      "Processing ME ...\n",
      "get centroid of ME\n",
      "creating centroid data frame\n",
      "loading ME building dataset\n",
      "ME spatial joining...\n",
      "write the output to .shp file...\n",
      "ME completed\n",
      "Processing MD ...\n",
      "get centroid of MD\n",
      "creating centroid data frame\n",
      "loading MD building dataset\n",
      "MD spatial joining...\n",
      "write the output to .shp file...\n",
      "MD completed\n",
      "Processing MA ...\n",
      "get centroid of MA\n",
      "creating centroid data frame\n",
      "loading MA building dataset\n",
      "MA spatial joining...\n",
      "write the output to .shp file...\n",
      "MA completed\n",
      "Processing MI ...\n",
      "get centroid of MI\n",
      "creating centroid data frame\n",
      "loading MI building dataset\n",
      "MI spatial joining...\n",
      "write the output to .shp file...\n",
      "MI completed\n",
      "Processing MN ...\n",
      "get centroid of MN\n",
      "creating centroid data frame\n",
      "loading MN building dataset\n",
      "MN spatial joining...\n",
      "write the output to .shp file...\n",
      "MN completed\n",
      "Processing MS ...\n",
      "get centroid of MS\n",
      "creating centroid data frame\n",
      "loading MS building dataset\n",
      "MS spatial joining...\n",
      "write the output to .shp file...\n",
      "MS completed\n",
      "Processing MO ...\n",
      "get centroid of MO\n",
      "creating centroid data frame\n",
      "loading MO building dataset\n",
      "MO spatial joining...\n",
      "write the output to .shp file...\n",
      "MO completed\n",
      "Processing NE ...\n",
      "get centroid of NE\n",
      "creating centroid data frame\n",
      "loading NE building dataset\n",
      "NE spatial joining...\n",
      "write the output to .shp file...\n",
      "NE completed\n",
      "Processing NV ...\n",
      "get centroid of NV\n",
      "creating centroid data frame\n",
      "loading NV building dataset\n",
      "NV spatial joining...\n",
      "write the output to .shp file...\n",
      "NV completed\n",
      "Processing NH ...\n",
      "get centroid of NH\n",
      "creating centroid data frame\n",
      "loading NH building dataset\n",
      "NH spatial joining...\n",
      "write the output to .shp file...\n",
      "NH completed\n",
      "Processing NJ ...\n",
      "get centroid of NJ\n",
      "creating centroid data frame\n",
      "loading NJ building dataset\n",
      "NJ spatial joining...\n",
      "write the output to .shp file...\n",
      "NJ completed\n",
      "Processing NM ...\n",
      "get centroid of NM\n",
      "creating centroid data frame\n",
      "loading NM building dataset\n",
      "NM spatial joining...\n",
      "write the output to .shp file...\n",
      "NM completed\n",
      "Processing NY ...\n",
      "get centroid of NY\n",
      "creating centroid data frame\n",
      "loading NY building dataset\n",
      "NY spatial joining...\n",
      "write the output to .shp file...\n",
      "NY completed\n",
      "Processing NC ...\n",
      "get centroid of NC\n",
      "creating centroid data frame\n",
      "loading NC building dataset\n",
      "NC spatial joining...\n",
      "write the output to .shp file...\n",
      "NC completed\n",
      "Processing ND ...\n",
      "get centroid of ND\n",
      "creating centroid data frame\n",
      "loading ND building dataset\n",
      "ND spatial joining...\n",
      "write the output to .shp file...\n",
      "ND completed\n",
      "Processing OH ...\n",
      "get centroid of OH\n",
      "creating centroid data frame\n",
      "loading OH building dataset\n",
      "OH spatial joining...\n",
      "write the output to .shp file...\n",
      "OH completed\n",
      "Processing OK ...\n",
      "get centroid of OK\n",
      "creating centroid data frame\n",
      "loading OK building dataset\n",
      "OK spatial joining...\n",
      "write the output to .shp file...\n",
      "OK completed\n",
      "Processing OR ...\n",
      "get centroid of OR\n",
      "creating centroid data frame\n",
      "loading OR building dataset\n",
      "OR spatial joining...\n",
      "write the output to .shp file...\n",
      "OR completed\n",
      "Processing PA ...\n",
      "get centroid of PA\n",
      "creating centroid data frame\n",
      "loading PA building dataset\n",
      "PA spatial joining...\n",
      "write the output to .shp file...\n",
      "PA completed\n",
      "Processing RI ...\n",
      "get centroid of RI\n",
      "creating centroid data frame\n",
      "loading RI building dataset\n",
      "RI spatial joining...\n",
      "write the output to .shp file...\n",
      "RI completed\n",
      "Processing SC ...\n",
      "get centroid of SC\n",
      "creating centroid data frame\n",
      "loading SC building dataset\n",
      "SC spatial joining...\n",
      "write the output to .shp file...\n",
      "SC completed\n",
      "Processing SD ...\n",
      "get centroid of SD\n",
      "creating centroid data frame\n",
      "loading SD building dataset\n",
      "SD spatial joining...\n",
      "write the output to .shp file...\n",
      "SD completed\n",
      "Processing TN ...\n",
      "get centroid of TN\n",
      "creating centroid data frame\n",
      "loading TN building dataset\n",
      "TN spatial joining...\n",
      "write the output to .shp file...\n",
      "TN completed\n",
      "Processing TX ...\n",
      "get centroid of TX\n",
      "creating centroid data frame\n",
      "loading TX building dataset\n",
      "TX spatial joining...\n",
      "write the output to .shp file...\n",
      "TX completed\n",
      "Processing UT ...\n",
      "get centroid of UT\n",
      "creating centroid data frame\n",
      "loading UT building dataset\n",
      "UT spatial joining...\n",
      "write the output to .shp file...\n",
      "UT completed\n",
      "Processing VA ...\n",
      "get centroid of VA\n",
      "creating centroid data frame\n",
      "loading VA building dataset\n",
      "VA spatial joining...\n",
      "write the output to .shp file...\n",
      "VA completed\n",
      "Processing WA ...\n",
      "get centroid of WA\n",
      "creating centroid data frame\n",
      "loading WA building dataset\n",
      "WA spatial joining...\n",
      "write the output to .shp file...\n",
      "WA completed\n",
      "Processing WY ...\n",
      "get centroid of WY\n",
      "creating centroid data frame\n",
      "loading WY building dataset\n",
      "WY spatial joining...\n",
      "write the output to .shp file...\n",
      "WY completed\n"
     ]
    }
   ],
   "source": [
    "for index, row in states.iterrows():\n",
    "    state_id = row['IL']\n",
    "    state_name = row['Illinois']\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(f'Processing {state_id} ...')\n",
    "    \n",
    "    os.chdir('C:/Users/utkge/Desktop/data/osm_height')\n",
    "    osm_filename = state_name + '.shp'\n",
    "    osm_gdf = gpd.read_file(osm_filename)\n",
    "    \n",
    "    print(f'get centroid of {state_id}')\n",
    "    centroid_points = osm_gdf.centroid\n",
    "    \n",
    "    print(f'creating centroid data frame')\n",
    "    centroid_gdf = gpd.GeoDataFrame(osm_gdf.drop('geometry', axis=1), geometry=centroid_points)\n",
    "\n",
    "    centroids = centroid_gdf[['geometry', 'Height']]\n",
    "    \n",
    "    print(f'loading {state_id} building dataset')\n",
    "    os.chdir('C:/Users/utkge/Desktop/data/buiding_height')\n",
    "    ms_filename = state_id + '.shp'\n",
    "    ms_gdf = gpd.read_file('AL.shp')\n",
    "    ms_gdf['index'] = ms_gdf.index\n",
    "\n",
    "    print(f'{state_id} spatial joining...')\n",
    "    gdf_joined = gpd.sjoin(ms_gdf, centroids, how='left', predicate='intersects')\n",
    "    gdf_joined['index'] = gdf_joined.index\n",
    "\n",
    "    print(f'write the output to .shp file...')\n",
    "    os.chdir('C:/Users/utkge/Desktop/data/valiadated')\n",
    "    shp_filename = ms_filename\n",
    "    gdf_joined.drop('index', axis=1).to_file(ms_filename)\n",
    "    print(f'{state_id} completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = centroid_gdf[['geometry', 'Height']]"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = '/media/hdd/Team-Drives/Buildings/Overture/'\n",
    "out_dir = '/media/hdd/Data/Buildings/Validation/'\n",
    "ms_dir = '/media/hdd/Team-Drives/Buildings/MS_USBuildingHeight/'"
>>>>>>> 76472dc1535b057a6ef41f75fc854cef39dadcea
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/utkge/Desktop/data/buiding_height')\n",
    "ms_gdf = gpd.read_file('AL.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   release           capture_da  HEIGHT  SQMETERS  \\\n",
      "0        2  3/26/2020-7/22/2020     NaN       NaN   \n",
      "1        2  3/26/2020-7/22/2020     NaN       NaN   \n",
      "2        1                  NaN     NaN       NaN   \n",
      "3        2  3/26/2020-7/22/2020     NaN       NaN   \n",
      "4        2  3/26/2020-7/22/2020     NaN       NaN   \n",
      "\n",
      "                                            geometry  index  \n",
      "0  POLYGON ((-84.95963 32.42189, -84.95964 32.421...      0  \n",
      "1  POLYGON ((-84.95964 32.42095, -84.95964 32.420...      1  \n",
      "2  POLYGON ((-84.96000 32.23523, -84.96000 32.235...      2  \n",
      "3  POLYGON ((-84.96025 32.42225, -84.96025 32.422...      3  \n",
      "4  POLYGON ((-84.96160 32.41921, -84.96180 32.419...      4  \n"
     ]
    }
   ],
   "source": [
    "ms_gdf['index'] = ms_gdf.index\n",
    "print(ms_gdf.head())"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = leafmap.find_files(in_dir, ext='shp', recursive=False)\n",
    "files"
>>>>>>> 76472dc1535b057a6ef41f75fc854cef39dadcea
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   release           capture_da  HEIGHT  SQMETERS  \\\n",
      "0        2  3/26/2020-7/22/2020     NaN       NaN   \n",
      "1        2  3/26/2020-7/22/2020     NaN       NaN   \n",
      "2        1                  NaN     NaN       NaN   \n",
      "3        2  3/26/2020-7/22/2020     NaN       NaN   \n",
      "4        2  3/26/2020-7/22/2020     NaN       NaN   \n",
      "\n",
      "                                            geometry  index  index_right  \\\n",
      "0  POLYGON ((-84.95963 32.42189, -84.95964 32.421...      0          NaN   \n",
      "1  POLYGON ((-84.95964 32.42095, -84.95964 32.420...      1          NaN   \n",
      "2  POLYGON ((-84.96000 32.23523, -84.96000 32.235...      2          NaN   \n",
      "3  POLYGON ((-84.96025 32.42225, -84.96025 32.422...      3          NaN   \n",
      "4  POLYGON ((-84.96160 32.41921, -84.96180 32.419...      4          NaN   \n",
      "\n",
      "   Height  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n"
     ]
    }
   ],
   "source": [
    "gdf_joined = gpd.sjoin(ms_gdf, centroids, how='left', predicate='intersects')\n",
    "gdf_joined['index'] = gdf_joined.index\n",
    "print(gdf_joined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/utkge/Desktop/data/valiadated')\n",
    "gdf_joined.drop('index', axis=1).to_file('al.shp')"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "\n",
    "    start_time = time.time()\n",
    "    basename = os.path.basename(file)\n",
    "    print(f'Processing {basename} ...')\n",
    "    out_file = os.path.join(out_dir, basename)\n",
    "    state_id = basename[-6:-4].upper()\n",
    "    out_shp = os.path.join(out_dir, basename)\n",
    "\n",
    "    ms_height = os.path.join(ms_dir, state_id + '.zip') \n",
    "\n",
    "    print(f'Loading {basename} ...')\n",
    "    om_gdf = gpd.read_file(file)\n",
    "\n",
    "    print('Creating Overture centroids ...')\n",
    "    centroid_points = om_gdf.centroid\n",
    "    centroid_gdf = gpd.GeoDataFrame(om_gdf.drop('geometry', axis=1), geometry=centroid_points)\n",
    "    centroids = centroid_gdf[['geometry', 'est_height']]\n",
    "    # print(centroids.head())\n",
    "\n",
    "    print(f'Loading MS Buildings {state_id} ...')\n",
    "    ms_gdf = gpd.read_file(ms_height)\n",
    "    ms_gdf = ms_gdf[ms_gdf['HEIGHT'] > 0]\n",
    "    ms_gdf['index'] = ms_gdf.index\n",
    "\n",
    "    print('Joining MS Buildings with Overture centroids ...')\n",
    "    gdf_joined = gpd.sjoin(ms_gdf, centroids, how='left', predicate='intersects')\n",
    "    gdf_joined['index'] = gdf_joined.index\n",
    "\n",
    "\n",
    "    # calculate mean height\n",
    "    gdf_joined_mean = gdf_joined.groupby('index')['est_height'].mean()\n",
    "    # gdf_joined_mean.head()\n",
    "\n",
    "    # join mean height column to ms_gdf\n",
    "    gdf_pts_height = ms_gdf.merge(gdf_joined_mean, on='index', how='left')\n",
    "    # gdf_pts_height.head()\n",
    "\n",
    "    # mean height is not null\n",
    "    gdf_pts_height_notnull = gdf_pts_height[gdf_pts_height['est_height'].notnull()]\n",
    "    # gdf_pts_height_notnull.head()\n",
    "\n",
    "    # extract rows where mean height is null\n",
    "    gdf_pts_height_null = gdf_pts_height[gdf_pts_height['est_height'].isnull()].drop(['est_height'], axis=1)\n",
    "    # gdf_pts_height_null.head()\n",
    "\n",
    "    print('Joining MS Buildings with ORNL polygons ...')\n",
    "    gdf_poly_height_sj = gpd.sjoin(gdf_pts_height_null, om_gdf, how='left', predicate='intersects')\n",
    "    gdf_poly_height_mean = gdf_poly_height_sj.groupby('index')['est_height'].mean()\n",
    "\n",
    "    # join mean height column to ms_gdf where mean height is null\n",
    "    gdf_poly_height = gdf_pts_height_null.merge(gdf_poly_height_mean, on='index', how='left')\n",
    "    # gdf_poly_height.head()\n",
    "\n",
    "    # concat two dataframes (point height and polygon height)\n",
    "    gdf_height = pd.concat([gdf_pts_height_notnull, gdf_poly_height])\n",
    "    gdf_height.sort_values('index', inplace=True)\n",
    "    # gdf_height\n",
    "\n",
    "    gdf_final = gdf_height[gdf_height['est_height'].notnull() & gdf_height['HEIGHT'].notnull()]\n",
    "    # gdf_final\n",
    "\n",
    "    print(f'Writing {basename} ...')\n",
    "    if not os.path.exists(os.path.dirname(out_shp)):\n",
    "        os.makedirs(os.path.dirname(out_shp))\n",
    "\n",
    "    schema = {'geometry': 'Polygon',\n",
    "    'properties': {'AREA': 'float:10.2',\n",
    "                    'HEIGHT': 'float:4.2',\n",
    "                    'SQMETERS': 'float:10.2',\n",
    "                    'est_height': 'float:4.2',}}\n",
    "\n",
    "    gdf_final.drop('index', axis=1).to_file(out_shp, schema=schema)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_minutes = (end_time - start_time) / 60\n",
    "    print(f'Finished {state_id} in {elapsed_minutes:.2f} minutes.')"
>>>>>>> 76472dc1535b057a6ef41f75fc854cef39dadcea
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "geos",
=======
   "display_name": "geo",
>>>>>>> 76472dc1535b057a6ef41f75fc854cef39dadcea
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
<<<<<<< HEAD
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd710834888dbcc484349dc268d4958684bb1cdcb5a66528dfc0f336f2cdf10a"
   }
  }
=======
  "orig_nbformat": 4
>>>>>>> 76472dc1535b057a6ef41f75fc854cef39dadcea
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
