{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import leafmap\n",
    "import zipfile\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/giswqs/data/main/us/us_states.csv'\n",
    "states = pd.read_csv(url)\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_id = 'WY'\n",
    "in_dir = '/media/hdd/Team-Drives/Buildings/'\n",
    "out_dir = '/media/hdd/Data/Buildings'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornl_files = leafmap.find_files(os.path.join(in_dir, 'USA_Structures'), ext='.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in states.iterrows():\n",
    "    state_id = row['id']\n",
    "    state_name = row['name']\n",
    "    out_shp = os.path.join(out_dir, f'Height/{state_id}.shp')\n",
    "\n",
    "    start_time = time.time()\n",
    "    # if state_id != 'WY':\n",
    "    #     continue\n",
    "    \n",
    "    if os.path.exists(out_shp):\n",
    "        continue\n",
    "\n",
    "    print(f'Processing {state_id} ...')\n",
    "    for file in ornl_files:\n",
    "        if file.endswith(state_id + '.zip'):\n",
    "            state = file\n",
    "            break\n",
    "    \n",
    "\n",
    "    ornl_dir = os.path.join(out_dir, 'USA_Structures')\n",
    "    print(f'Extracting USA Structures {state_id} ...')\n",
    "    with zipfile.ZipFile(state, 'r') as zip_ref:\n",
    "        zip_ref.extractall(ornl_dir)\n",
    "\n",
    "    basename = os.path.basename(state).replace('.zip', '')\n",
    "    db_name= f'{state_id}_Structures.gdb'\n",
    "    db_path = os.path.join(ornl_dir, basename, db_name)\n",
    "    if not os.path.exists(db_path):\n",
    "        try:\n",
    "            if state_id not in ['CA', 'TX', 'LA']:\n",
    "                basename = basename + '_OCC'\n",
    "                db_name = f'{state_id}_Structures_OCC.gdb'\n",
    "                db_path = os.path.join(ornl_dir, basename, db_name)\n",
    "            elif state_id == 'CA':\n",
    "                basename = basename + '_OCC'\n",
    "                db_name = f'{state_id}_Structures.gdb'\n",
    "                db_path = os.path.join(ornl_dir, basename, db_name)\n",
    "            elif state_id == 'LA':\n",
    "                basename = basename + 'v2_OCC'\n",
    "                db_name = f'{state_id}_Structures_v2_OCC.gdb'\n",
    "                db_path = os.path.join(ornl_dir, basename, db_name)\n",
    "            elif state_id == 'TX':\n",
    "                basename = basename + 'v2_OCC'\n",
    "                db_name = f'{state_id}_Structures_v2_OCC.gdb'\n",
    "                db_path = os.path.join(ornl_dir, basename, db_name)                \n",
    "        except:\n",
    "            raise Exception(f'File {db_path} does not exists.')\n",
    "    \n",
    "    print(f'Loading USA Structures {state_id} ...')\n",
    "    try:\n",
    "        ornl_gdf = gpd.read_file(db_path, layer=db_name.replace('.gdb', ''))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # for col in ornl_gdf.columns:\n",
    "    #     if ornl_gdf[col].dtype in ['datetime64[ns]', 'datetime64[ns, UTC]']:\n",
    "    #         ornl_gdf[col] = ornl_gdf[col].astype(str)\n",
    "\n",
    "    print('Creating centroids ...')\n",
    "    centroid_points = ornl_gdf.centroid\n",
    "    centroid_gdf = gpd.GeoDataFrame(ornl_gdf.drop('geometry', axis=1), geometry=centroid_points)\n",
    "    centroids = centroid_gdf[['geometry', 'HEIGHT', 'SQMETERS', 'IMAGE_DATE']]\n",
    "\n",
    "    geojson = f\"{in_dir}MS_USBuildingFootprints/{state_name.replace(' ', '')}.geojson.zip\"\n",
    "    if not os.path.exists(geojson):\n",
    "        raise Exception(f'File {geojson} does not exists.')\n",
    "    \n",
    "    print(f'Loading MS Buildings {state_id} ...')\n",
    "    ms_gdf = gpd.read_file(geojson)\n",
    "    ms_gdf['index'] = ms_gdf.index\n",
    "\n",
    "    print('Joining MS Buildings with ORNL centroids ...')\n",
    "    gdf_joined = gpd.sjoin(ms_gdf, centroids, how='left', predicate='intersects')\n",
    "    gdf_joined['index'] = gdf_joined.index\n",
    "\n",
    "    gdf_joined_mean = gdf_joined.groupby('index')['HEIGHT', 'SQMETERS'].mean()\n",
    "    gdf_pts_height = ms_gdf.merge(gdf_joined_mean, on='index', how='left')\n",
    "\n",
    "    gdf_pts_height_notnull = gdf_pts_height[gdf_pts_height['HEIGHT'].notnull()]\n",
    "    gdf_pts_height_null = gdf_pts_height[gdf_pts_height['HEIGHT'].isnull()].drop(['HEIGHT', 'SQMETERS'], axis=1)\n",
    "\n",
    "    print('Joining MS Buildings with ORNL polygons ...')\n",
    "    gdf_poly_height_sj = gpd.sjoin(gdf_pts_height_null, ornl_gdf, how='left', predicate='intersects')\n",
    "    gdf_poly_height_mean = gdf_poly_height_sj.groupby('index')['HEIGHT', 'SQMETERS'].mean()\n",
    "\n",
    "    gdf_poly_height = gdf_pts_height_null.merge(gdf_poly_height_mean, on='index', how='left')\n",
    "    gdf_height = pd.concat([gdf_pts_height_notnull, gdf_poly_height])\n",
    "\n",
    "    gdf_height.sort_values('index', inplace=True)\n",
    "\n",
    "    \n",
    "    print(f'Writing {state_id}.shp ...')\n",
    "    if not os.path.exists(os.path.dirname(out_shp)):\n",
    "        os.makedirs(os.path.dirname(out_shp))\n",
    "    gdf_height.drop('index', axis=1).to_file(out_shp)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_minutes = (end_time - start_time) / 60\n",
    "    print(f'Finished {state_id} in {elapsed_minutes:.2f} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = '/media/hdd/Team-Drives/Buildings/USA_Structures/Deliverable20211203WY.zip'\n",
    "out_dir = os.path.expanduser('~/Downloads')\n",
    "out_pts_dir = os.path.expanduser('~/Downloads/USA_Structures_PTS')\n",
    "out_building_height = os.path.expanduser('~/Downloads/Building_Height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_pts_dir):\n",
    "    os.makedirs(out_pts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_building_height):\n",
    "    os.makedirs(out_building_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(state, 'r') as zip_ref:\n",
    "    zip_ref.extractall(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = os.path.basename(state).replace('.zip', '')\n",
    "state_abbr = basename[-2:]\n",
    "db_name= f'{state_abbr}_Structures.gdb'\n",
    "db_path = os.path.join(out_dir, basename, db_name)\n",
    "if not os.path.exists(db_path):\n",
    "    raise Exception(f'File {db_path} does not exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornl_gdf = gpd.read_file(db_path, layer=db_name.replace('.gdb', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornl_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ornl_gdf.columns:\n",
    "    if ornl_gdf[col].dtype in ['datetime64[ns]', 'datetime64[ns, UTC]']:\n",
    "        ornl_gdf[col] = ornl_gdf[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornl_gdf.head(n=50).explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the centroids\n",
    "centroid_points = ornl_gdf.centroid\n",
    "\n",
    "# Create a new GeoDataFrame with the centroid points and the attributes from the original GeoDataFrame\n",
    "centroid_gdf = gpd.GeoDataFrame(ornl_gdf.drop('geometry', axis=1), geometry=centroid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = centroid_gdf[['geometry', 'HEIGHT', 'SQMETERS', 'IMAGE_DATE']]\n",
    "centroids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_name = db_name.replace('.gdb', '') + '_PTS.shp'\n",
    "shp_path = os.path.join(out_pts_dir, shp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids.to_file(shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson = '/media/hdd/Team-Drives/Buildings/MS_USBuildingFootprints/Wyoming.geojson.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gdf = gpd.read_file(geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_gdf['index'] = ms_gdf.index\n",
    "ms_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ms_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform spatial join based on intersecting polygons\n",
    "gdf_joined = gpd.sjoin(ms_gdf, centroids, how='left', predicate='intersects')\n",
    "gdf_joined['index'] = gdf_joined.index\n",
    "len(gdf_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_joined_mean = gdf_joined.groupby('index')['HEIGHT', 'SQMETERS'].mean()\n",
    "gdf_joined_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pts_height = ms_gdf.merge(gdf_joined_mean, on='index', how='left')\n",
    "gdf_pts_height.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_pts_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pts_height.drop('index', axis=1).to_file(os.path.join(out_building_height, f'{state_abbr}.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pts_height_notnull = gdf_pts_height[gdf_pts_height['HEIGHT'].notnull()]\n",
    "len(gdf_pts_height_notnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pts_height_notnull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pts_height_null = gdf_pts_height[gdf_pts_height['HEIGHT'].isnull()].drop(['HEIGHT', 'SQMETERS'], axis=1)\n",
    "len(gdf_pts_height_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_pts_height_null.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_poly_height_sj = gpd.sjoin(gdf_pts_height_null, ornl_gdf, how='left', predicate='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_poly_height_mean = gdf_poly_height_sj.groupby('index')['HEIGHT', 'SQMETERS'].mean()\n",
    "gdf_poly_height_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_poly_height = gdf_pts_height_null.merge(gdf_poly_height_mean, on='index', how='left')\n",
    "len(gdf_poly_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_poly_height.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf_height = pd.concat([gdf_pts_height_notnull, gdf_poly_height])\n",
    "len(gdf_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_height.sort_values('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_height.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_height.drop('index', axis=1).to_file(os.path.join(out_building_height, f'{state_abbr}.shp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
